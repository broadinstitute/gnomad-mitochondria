#!/usr/bin/env python
import argparse
import hail as hl
import logging
import re
import sys

from collections import Counter
from os.path import dirname
from textwrap import dedent

from gnomad.utils.annotations import age_hists_expr
from gnomad.utils.reference_genome import add_reference_sequence
from gnomad.utils.slack import slack_notifications
from gnomad.utils.vep import vep_struct_to_csq
from gnomad_qc.v3.resources.meta import meta  # pylint: disable=import-error
from gnomad.resources.grch38.gnomad import POPS
from gnomad.resources.grch38.reference_data import dbsnp, _import_dbsnp
from gnomad_mitochondria.pipeline.annotation_descriptions import (
    add_descriptions,
    adjust_descriptions,
)

# Github repo locations for imports:
# gnomad: https://github.com/broadinstitute/gnomad_methods
# gnomad_qc: https://github.com/broadinstitute/gnomad_qc

# Include NA in POPS to account for cases where population annotations are missing
POPS.append("NA")

RESOURCES = {
    "variant_context": "gs://gnomad-public-requester-pays/resources/mitochondria/variant_context/chrM_pos_ref_alt_context_categories.txt",
    "phylotree": "gs://gnomad-public-requester-pays/resources/mitochondria/phylotree/rCRS-centered_phylo_vars_final_update.txt",
    "pon_mt_trna": "gs://gnomad-public-requester-pays/resources/mitochondria/trna_predictions/pon_mt_trna_predictions_08_27_2020.txt",
    "mitotip": "gs://gnomad-public-requester-pays/resources/mitochondria/trna_predictions/mitotip_scores_08_27_2020.txt",
}


logging.basicConfig(
    format="%(asctime)s (%(name)s %(lineno)s): %(message)s",
    datefmt="%m/%d/%Y %I:%M:%S %p",
)
logger = logging.getLogger("add annotations")
logger.setLevel(logging.INFO)

logger.info("Setting hail flag to avoid array index out of bounds error error...")
# Setting this flag isn't generally recommended, but is needed (since at least Hail version 0.2.75) to avoid an array index out of bounds error until changes are made in future versions of Hail
# TODO: reassess if this flag is still needed for future versions of Hail
hl._set_flags(no_whole_stage_codegen="1")


def add_genotype(mt_path: str, min_hom_threshold: float = 0.95) -> hl.MatrixTable:
    """
    Add in genotype annotation based on heteroplasmy level.

    If the heteroplasmy level is above the min_hom_threshold, set the genotype to 1/1.
    If the heteroplasmy level is less than the min_hom_threshold, but greater than 0, set the genotype to 0/1.
    Otherwise set the genotype to 0/0.

    :param mt_path: Path to the MatrixTable (this MatrixTable can be generated by running combine_vcfs.py)
    :param min_hom_threshold: Minimum heteroplasmy level to define a variant as homoplasmic
    :return: MatrixTable with GT field added
    """
    logger.info("Reading in MT...")
    mt = hl.read_matrix_table(mt_path)

    # Add in genotype (GT) based on min_hom_threshold
    mt = mt.annotate_entries(
        GT=(
            hl.case()
            .when((mt.HL < min_hom_threshold) & (mt.HL > 0.0), hl.parse_call("0/1"))
            .when(mt.HL >= min_hom_threshold, hl.parse_call("1/1"))
            .when(mt.HL == 0, hl.parse_call("0/0"))
            .default(hl.missing(hl.tcall))
        ),
    )

    return mt


def add_variant_context(input_mt: hl.MatrixTable) -> hl.MatrixTable:
    """
    Add variant context annotations to the MatrixTable.

    This fucntion adds in information on regions/strand for SNPs that can be useful for determining mutational signatures.

    :param input_mt: MatrixTable
    :return: MatrixTable with variant context information added
    """
    # Read in variant context data
    vc_ht = hl.import_table(RESOURCES["variant_context"], impute=True)

    # Split columns into separate annotations
    vc_ht = vc_ht.annotate(
        ref=vc_ht["POS.REF.ALT"].split("\.")[1],
        alt=vc_ht["POS.REF.ALT"].split("\.")[2],
        strand=vc_ht.Context_category.split("_")[-1],
        variant=vc_ht.Context_category.split("_")[0],
    )

    # Rename and select certain columns
    vc_ht = vc_ht.rename({"MT_POS": "pos", "Annotation": "region"})
    vc_ht = vc_ht.select("pos", "ref", "alt", "strand", "region", "variant")

    # Key by locus and allele
    vc_ht = vc_ht.key_by(
        locus=hl.locus("MT", vc_ht.pos, reference_genome="GRCh37"),
        alleles=[vc_ht.ref, vc_ht.alt],
    )

    # Annotate original mt with variant context information
    input_mt = input_mt.annotate_rows(**vc_ht[input_mt.locus, input_mt.alleles])
    input_mt = input_mt.annotate_rows(
        variant_context=hl.str(input_mt.variant) + "_" + hl.str(input_mt.strand)
    )
    input_mt = input_mt.drop("pos", "ref", "alt", "strand", "variant")

    return input_mt


def add_gnomad_metadata(input_mt: hl.MatrixTable) -> hl.MatrixTable:
    """
    Add select gnomAD metadata to the MatrixTable.

    :param input_mt: MatrixTable
    :return: MatrixTable with select gnomAD metadata added
    """
    # TODO: Add option here to accomodate non-gnomAD metadata
    genome_meta_ht = meta.versions["3.1"].ht()

    genome_meta_struct = genome_meta_ht[input_mt.s]

    input_mt = input_mt.annotate_cols(
        release=genome_meta_struct.release,
        hard_filters=genome_meta_struct.sample_filters.hard_filters,
        research_project=genome_meta_struct.project_meta.research_project,
        project_id=genome_meta_struct.project_meta.project_id,
        product=genome_meta_struct.project_meta.product,
        sample_pi=genome_meta_struct.project_meta.sample_pi,
        sex_karyotype=genome_meta_struct.sex_imputation.sex_karyotype,
        age=hl.if_else(
            hl.is_defined(genome_meta_struct.project_meta.age),
            genome_meta_struct.project_meta.age,
            genome_meta_struct.project_meta.age_alt,
        ),
        broad_external=genome_meta_struct.project_meta.broad_external,
        pop=genome_meta_struct.population_inference.pop,
    )

    return input_mt


def add_age_and_pop(input_mt: hl.MatrixTable, participant_data: str) -> hl.MatrixTable:
    """
    Add sample-level metadata for age and pop to `input_mt`.

    :param input_mt: MatrixTable
    :param participant_data: Path to metadata file downloaded from Terra that contains sample age and pop information
    :return: MatrixTable with select age and pop annotations added
    """
    ht = hl.import_table(
        participant_data, types={"age": hl.tint32, "pop": hl.tstr},
    ).key_by("s")

    ht = ht.select("age", "pop")

    input_mt = input_mt.annotate_cols(**ht[input_mt.col_key])

    # If a sample doesn't have an annotated population, set it to the string "NA"
    input_mt = input_mt.annotate_cols(
        pop=hl.if_else(hl.is_missing(input_mt.pop), "NA", input_mt.pop)
    )

    return input_mt


def filter_by_copy_number(
    input_mt: hl.MatrixTable, keep_all_samples: bool = False
) -> hl.MatrixTable:
    """
    Calculate the mitochondrial copy number based on mean mitochondrial coverage and median nuclear coverage. Filter out samples with more extreme copy numbers.

    Note that median and mean coverage for mitochondria are very similar. Mean mitochondria coverage was used based on metrics available at the time, but releases will switch to using median mitochondria coverage.

    :param hl.MatrixTable input_mt: MatrixTable
    :param keep_all_samples: If True, keep all samples (calculate mitochondrial copy number, but do not filter any samples based on this metric)
    :return: MatrixTable filtered to samples with a copy number of at least 50 and less than 500, number samples below 50 removed, number samples above 500 removed
    """
    # Calculate mitochondrial copy number, if median autosomal coverage is not present default to a wgs_median_coverage of 30x
    input_mt = input_mt.annotate_cols(
        mito_cn=2
        * input_mt.mt_mean_coverage
        / hl.if_else(
            hl.is_missing(input_mt.wgs_median_coverage),
            30,
            input_mt.wgs_median_coverage,
        )
    )
    n_removed_below_cn = input_mt.aggregate_cols(
        hl.agg.count_where(input_mt.mito_cn < 50)
    )
    n_removed_above_cn = input_mt.aggregate_cols(
        hl.agg.count_where(input_mt.mito_cn > 500)
    )

    if not keep_all_samples:
        # Remove samples with a mitochondrial copy number below 50 or greater than 500
        input_mt = input_mt.filter_cols(
            (input_mt.mito_cn >= 50) & (input_mt.mito_cn <= 500)
        )
    input_mt = input_mt.filter_rows(hl.agg.any(input_mt.HL > 0))

    return input_mt, n_removed_below_cn, n_removed_above_cn


def filter_by_contamination(
    input_mt: hl.MatrixTable, output_dir: str, keep_all_samples: bool = False
) -> hl.MatrixTable:
    """
    Calculate contamination based on internal algorithm and filter out samples with contamination above 2%.

    Contamination takes into account:
    a) mitochondria contamination output by HaploCheck
    b) nuclear contamination (freemix) output by VerifyBamID
    c) an internal algorithm with utilizes the PASS haplogroup-defining variants which should be homoplasmic (100% alternate alleles), but in contaminated samples show multiple alleles with heteroplasmy 85-99.8%

    :param input_mt: MatrixTable
    :param output_dir: Output directory to which results should be written
    :param keep_all_samples: If True, keep all samples (calculate contamination, but do not filter any samples based on this metric)
    :return: MatrixTable filtered to samples without contamination, number of contaminated samples removed
    """
    # Generate expression for genotypes with >= 85% heteroplasmy and no FT filters at haplogroup-defining sites that are not filtered as artifact-prone sites
    over_85_expr = (
        (input_mt.HL >= 0.85)
        & (input_mt.FT == {"PASS"})
        & input_mt.hap_defining_variant
        & ~hl.str(input_mt.filters).contains("artifact_prone_site")
    )

    input_mt = input_mt.annotate_cols(
        over_85_mean=hl.agg.filter(over_85_expr, hl.agg.mean(input_mt.HL)),
        over_85_count=hl.agg.filter(
            over_85_expr, hl.agg.count_where(hl.is_defined(input_mt.HL))
        ),
        bt_85_and_99_mean=hl.agg.filter(
            over_85_expr & (input_mt.HL <= 0.998), hl.agg.mean(input_mt.HL)
        ),
        bt_85_and_99_count=hl.agg.filter(
            over_85_expr & (input_mt.HL <= 0.998),
            hl.agg.count_where(hl.is_defined(input_mt.HL)),
        ),
    )

    input_mt = input_mt.annotate_cols(
        contam_high_het=hl.if_else(
            input_mt.bt_85_and_99_count >= 3,
            1 - input_mt.bt_85_and_99_mean,
            1 - input_mt.over_85_mean,
        )
    )

    # If contam_high_het is nan, set to 0 (to avoid filtering out missing values which would be more common with haplogroups closer to the reference haplogroup)
    input_mt = input_mt.annotate_cols(
        contam_high_het=hl.if_else(
            hl.is_nan(input_mt.contam_high_het), 0, input_mt.contam_high_het
        )
    )

    # Find samples on border of .02 that may flip between < 0.02 and > 0.02 from issues with floating point precision and mark these samples for removal
    epsilon = 0.000001
    border_samples = input_mt.aggregate_cols(
        hl.agg.filter(
            (input_mt.contam_high_het > (0.02 - epsilon))
            & (input_mt.contam_high_het < (0.02 + epsilon)),
            hl.agg.collect((input_mt.s)),
        )
    )

    border_samples = (
        hl.literal(border_samples) if border_samples else hl.empty_array(hl.tstr)
    )

    # Add annotation to keep only samples with a contamination less than 2%
    input_mt = input_mt.annotate_cols(
        keep=(input_mt.contamination < 0.02)
        & (input_mt.freemix_percentage < 2)
        & (input_mt.contam_high_het < 0.02)
        & ~border_samples.contains(input_mt.s)
    )
    # Save sample contamination information to separate file
    n_contaminated = input_mt.aggregate_cols(hl.agg.count_where(~input_mt.keep))

    sample_data = input_mt.select_cols(
        "contamination",
        "freemix_percentage",
        "contam_high_het",
        "over_85_mean",
        "over_85_count",
        "bt_85_and_99_mean",
        "bt_85_and_99_count",
        "keep",
    )
    data_export = sample_data.cols()
    data_export.export(f"{output_dir}/sample_contamination.tsv")

    if not keep_all_samples:
        logger.info(
            "Removing %d samples with contamination above 2 percent", n_contaminated
        )
        input_mt = input_mt.filter_cols(input_mt.keep)
    input_mt = input_mt.drop("keep")

    input_mt = input_mt.filter_rows(hl.agg.any(input_mt.HL > 0))

    return input_mt, n_contaminated


def add_terra_metadata(
    input_mt: hl.MatrixTable, participant_data: str
) -> hl.MatrixTable:
    """
    Add Terra metadata to the MatrixTable.

    The participant_data file can be obtained by downloading the participant data after running Mutect2 in Terra. This file should contain the following columns:
        - entity:participant_id: Participant ID uploaded to Terra by user
        - s: Sample ID uploaded to Terra by user
        - contamination: Output by Mutect2, gives the estimate of mitochondrial contamination
        - freemix_percentage: Uploaded to Terra by user, can be calculated with VerifyBamID
        - major_haplogroup: Output by Mutect2 which utilizes Haplogrep
        - wgs_median_coverage: Uploaded to Terra by user, can be calculated with Picard's CollectWgsMetrics
        - mt_mean_coverage: Output by Mutect2, gives the mean mitochondrial coverage

    :param input_mt: MatrixTable
    :param participant_data: Path to metadata file downloaded from Terra
    :return: MatrixTable with Terra metadata annotations added
    """
    # Add haplogroup and Mutect2/Terra output annotations
    ht = hl.import_table(
        participant_data,
        types={
            "contamination": hl.tfloat64,
            "freemix_percentage": hl.tfloat64,
            "mt_mean_coverage": hl.tfloat64,
            "wgs_median_coverage": hl.tfloat64,
        },
        missing="",
    ).key_by("s")
    ht = ht.rename({"entity:participant_id": "participant_id"})

    ht = ht.select(
        "participant_id",
        "contamination",
        "freemix_percentage",
        "major_haplogroup",
        "wgs_median_coverage",
        "mt_mean_coverage",
    )

    input_mt = input_mt.annotate_cols(**ht[input_mt.s])

    # Annotate the high level haplogroup by taking the first letter, with the exception of H and L haplogroups which are more commonly referred to using the first two letters
    input_mt = input_mt.annotate_cols(
        hap=hl.if_else(
            input_mt.major_haplogroup.startswith("HV")
            | input_mt.major_haplogroup.startswith("L"),
            input_mt.major_haplogroup[0:2],
            input_mt.major_haplogroup[0],
        )
    )

    return input_mt


def add_hap_defining(input_mt: hl.MatrixTable) -> hl.MatrixTable:
    """
    Add bool on whether or not a variant is a haplogroup-defining variant to the MatrixTable.

    Haplogroup-defining annotations were obtained from PhyloTree Build 17.

    :param input_mt: MatrixTable
    :return: MatrixTable with annotation on whether or not the variant is haplogroup-defining added
    """
    # TODO: move dataset location
    hap_defining_variants = hl.import_table(RESOURCES["phylotree"])

    hap_defining = hl.literal(set(hap_defining_variants.variant.collect()))
    input_mt = input_mt.annotate_rows(
        variant_collapsed=input_mt.alleles[0]
        + hl.str(input_mt.locus.position)
        + input_mt.alleles[1]
    )
    input_mt = input_mt.annotate_rows(
        hap_defining_variant=hap_defining.contains(input_mt.variant_collapsed)
    )  # set hap_defining_variant to True or False

    return input_mt


def add_trna_predictions(input_mt: hl.MatrixTable) -> hl.MatrixTable:
    """
    Add tRNA predictions on pathogenicity from PON-mt-tRNA and MitoTIP to the MatrixTable.

    :param input_mt: MatrixTable
    :return: MatrixTable with tRNA predictions of pathogenicity added
    """
    # Add PON-mt-tRNA predictions
    pon_predictions = hl.import_table(RESOURCES["pon_mt_trna"])

    # If reference allele from fasta doesn't match Reference_nucleotide, PON-mt-tRNA is reporting the allele of opposite strand and need to get reverse complement for ref and alt
    add_reference_sequence(hl.get_reference("GRCh37"))
    pon_predictions = pon_predictions.annotate(
        ref=hl.get_sequence(
            "MT", hl.int(pon_predictions.mtDNA_position), reference_genome="GRCh37"
        )
    )
    pon_predictions = pon_predictions.annotate(
        alt=hl.if_else(
            pon_predictions.Reference_nucleotide == pon_predictions.ref,
            pon_predictions.New_nucleotide,
            hl.reverse_complement(pon_predictions.New_nucleotide),
        )
    )
    pon_predictions = pon_predictions.key_by(
        variant_id=pon_predictions.ref
        + hl.str(pon_predictions.mtDNA_position)
        + pon_predictions.alt
    )
    input_mt = input_mt.annotate_rows(
        pon_mt_trna_prediction=pon_predictions[input_mt.variant_collapsed]
        .Classification.lower()
        .replace(" ", "_"),
        pon_ml_probability_of_pathogenicity=hl.float(
            pon_predictions[input_mt.variant_collapsed].ML_probability_of_pathogenicity
        ),
    )

    # Add MitoTIP predictions
    mitotip_predictions = hl.import_table(RESOURCES["mitotip"])
    mitotip_predictions = mitotip_predictions.key_by(
        variant_id=mitotip_predictions.rCRS
        + hl.str(mitotip_predictions.Position)
        + mitotip_predictions.Alt
    )
    input_mt = input_mt.annotate_rows(
        mitotip_score=hl.float(
            mitotip_predictions[input_mt.variant_collapsed].MitoTIP_Score
        )
    )
    # Set pathogenicity based on MitoTIP scores, classifications obtained from MitoTIP's website
    input_mt = input_mt.annotate_rows(
        mitotip_trna_prediction=(
            hl.case()
            .when(input_mt.mitotip_score > 16.25, "likely_pathogenic")
            .when(
                (input_mt.mitotip_score <= 16.25) & (input_mt.mitotip_score > 12.66),
                "possibly_pathogenic",
            )
            .when(
                (input_mt.mitotip_score <= 12.66) & (input_mt.mitotip_score >= 8.44),
                "possibly_benign",
            )
            .when((input_mt.mitotip_score < 8.44), "likely_benign")
            .or_missing()
        )
    )

    return input_mt


def get_indel_expr(input_mt: hl.MatrixTable) -> hl.expr.BooleanExpression:
    """
    Generate expression for filtering to indels that should be used to evaluate indel stacks.

    To be considered a variant to be used to evaluate indel stacks, the variant should:
    a) be an indel
    b) have a heteroplasmy level >= 0.01 and <= 0.95
    c) have a PASS genotype

    :param input_mt: MatrixTable
    :return: Expression to be used for determining if a variant is an indel that should to be used to evaluate indel stacks
    """
    indel_expr = (
        hl.is_indel(input_mt.alleles[0], input_mt.alleles[1])
        & (input_mt.HL <= 0.95)
        & (input_mt.HL >= 0.01)
        & (input_mt.FT == {"PASS"})
    )

    return indel_expr


def generate_expressions(
    input_mt: hl.MatrixTable, min_hom_threshold: float = 0.95
) -> hl.MatrixTable:
    """
    Create expressions to use for annotating the MatrixTable.

    The expressions include AC, AN, AF, filtering allele frequency (FAF) split by homplasmic/heteroplasmic, haplgroup, and population.
    Also includes calcuations of mean DP, MQ, and TLOD.

    :param input_mt: MatrixTable
    :param min_hom_threshold: Minimum heteroplasmy level to define a variant as homoplasmic
    :return: Tuple of hail expressions
    """
    # Calculate AC and AN
    AC = hl.agg.count_where((input_mt.HL > 0.0))
    AN = hl.agg.count_where(hl.is_defined(input_mt.HL))
    # Note: if AN is zero, AFs will evaluate to NaN, which may need to be converted to zero for downstream tools
    AF = AC / AN

    # Calculate AC for het and hom variants, and histogram for HL
    AC_hom = hl.agg.count_where(input_mt.HL >= min_hom_threshold)
    AC_het = hl.agg.count_where((input_mt.HL < min_hom_threshold) & (input_mt.HL > 0.0))
    HL_hist = hl.agg.filter(input_mt.HL > 0, hl.agg.hist(input_mt.HL, 0, 1, 10))
    DP_hist_alt = hl.agg.filter(
        input_mt.GT.is_non_ref(), hl.agg.hist(input_mt.DP, 0, 2000, 10)
    )
    DP_hist_all = hl.agg.hist(input_mt.DP, 0, 2000, 10)
    DP_mean = hl.agg.mean(input_mt.DP)
    MQ_mean = hl.agg.mean(input_mt.MQ)
    TLOD_mean = hl.agg.mean(input_mt.TLOD)

    # Calculate AF
    # Note: if AN is zero, AFs will evaluate to NaN, which may need to be converted to zero for downstream tools
    AF_hom = AC_hom / AN
    AF_het = AC_het / AN

    # Calculate max individual heteroplasmy
    max_HL = hl.agg.max(input_mt.HL)

    # Haplogroup annotations
    pre_hap_AC = hl.agg.group_by(input_mt.hap, AC)
    pre_hap_AN = hl.agg.group_by(input_mt.hap, AN)
    pre_hap_AF = hl.agg.group_by(input_mt.hap, AF)
    pre_hap_AC_het = hl.agg.group_by(input_mt.hap, AC_het)
    pre_hap_AC_hom = hl.agg.group_by(input_mt.hap, AC_hom)
    pre_hap_AF_hom = hl.agg.group_by(input_mt.hap, AF_hom)
    pre_hap_AF_het = hl.agg.group_by(input_mt.hap, AF_het)
    pre_hap_HL_hist = hl.agg.group_by(input_mt.hap, HL_hist.bin_freq)
    pre_hap_FAF = hl.agg.group_by(
        input_mt.hap,
        hl.experimental.filtering_allele_frequency(hl.int32(AC), hl.int32(AN), 0.95),
    )
    pre_hap_FAF_hom = hl.agg.group_by(
        input_mt.hap,
        hl.experimental.filtering_allele_frequency(
            hl.int32(AC_hom), hl.int32(AN), 0.95
        ),
    )

    # population annotations
    pre_pop_AC = hl.agg.group_by(input_mt.pop, AC)
    pre_pop_AN = hl.agg.group_by(input_mt.pop, AN)
    pre_pop_AF = hl.agg.group_by(input_mt.pop, AF)
    pre_pop_AC_het = hl.agg.group_by(input_mt.pop, AC_het)
    pre_pop_AC_hom = hl.agg.group_by(input_mt.pop, AC_hom)
    pre_pop_AF_hom = hl.agg.group_by(input_mt.pop, AF_hom)
    pre_pop_AF_het = hl.agg.group_by(input_mt.pop, AF_het)
    pre_pop_HL_hist = hl.agg.group_by(input_mt.pop, HL_hist.bin_freq)

    return hl.struct(
        AC=AC,
        AN=AN,
        AF=AF,
        AC_hom=AC_hom,
        AC_het=AC_het,
        hl_hist=HL_hist,
        dp_hist_all=DP_hist_all,
        dp_hist_alt=DP_hist_alt,
        dp_mean=DP_mean,
        mq_mean=MQ_mean,
        tlod_mean=TLOD_mean,
        AF_hom=AF_hom,
        AF_het=AF_het,
        max_hl=max_HL,
        pre_hap_AC=pre_hap_AC,
        pre_hap_AN=pre_hap_AN,
        pre_hap_AF=pre_hap_AF,
        pre_hap_AC_het=pre_hap_AC_het,
        pre_hap_AF_het=pre_hap_AF_het,
        pre_hap_AC_hom=pre_hap_AC_hom,
        pre_hap_AF_hom=pre_hap_AF_hom,
        pre_hap_hl_hist=pre_hap_HL_hist,
        pre_hap_faf=pre_hap_FAF,
        pre_hap_faf_hom=pre_hap_FAF_hom,
        pre_pop_AN=pre_pop_AN,
        pre_pop_AC_het=pre_pop_AC_het,
        pre_pop_AF_het=pre_pop_AF_het,
        pre_pop_AC_hom=pre_pop_AC_hom,
        pre_pop_AF_hom=pre_pop_AF_hom,
        pre_pop_hl_hist=pre_pop_HL_hist,
    )


def standardize_haps(
    input_mt: hl.MatrixTable, annotation: str, haplogroup_order: list
) -> list:
    """
    Convert the dictionary of haplogroup annotations into an array of values in a predefined haplogroup order.

    :param input_mt: MatrixTable
    :param annotation: Annotation to convert and sort
    :param haplogroup_order: Order in which to sort the haplogroups
    :return: Sorted list of haplogroup annotations (the values of the dictionary)
    """
    # Converts haplogroup dictionary to sorted array
    value = [input_mt[annotation][x] for x in haplogroup_order]

    return value


def standardize_pops(
    input_mt: hl.MatrixTable, annotation: str, population_order: list
) -> list:
    """
    Convert the dictionary of population annotations into an array of values in a predefined population order.

    :param input_mt: MatrixTable
    :param annotation: Annotation to convert and sort
    :param population_order: Order in which to sort the populations
    :return: Sorted list of population annotations (the values of the dictionary)
    """
    # Converts haplogroup dictionary to sorted array
    value = [input_mt[annotation][x] for x in population_order]

    return value


def add_quality_histograms(input_mt: hl.MatrixTable) -> hl.MatrixTable:
    """
    Add histogram annotations for quality metrics to the MatrixTable.

    :param input_mt: MatrixTable
    :return: MatrixTable annotated with quality metric histograms
    """
    # Generate histogram for site quality metrics across all variants
    # TODO: decide on bin edges
    dp_hist_all_variants = input_mt.aggregate_rows(
        hl.agg.hist(input_mt.dp_mean, 0, 4000, 40)
    )
    input_mt = input_mt.annotate_globals(
        dp_hist_all_variants_bin_freq=dp_hist_all_variants.bin_freq,
        dp_hist_all_variants_n_larger=dp_hist_all_variants.n_larger,
        dp_hist_all_variants_bin_edges=dp_hist_all_variants.bin_edges,
    )

    mq_hist_all_variants = input_mt.aggregate_rows(
        hl.agg.hist(input_mt.mq_mean, 0, 80, 40)
    )  # is 80 the actual max value here?
    input_mt = input_mt.annotate_globals(
        mq_hist_all_variants_bin_freq=mq_hist_all_variants.bin_freq,
        mq_hist_all_variants_n_larger=mq_hist_all_variants.n_larger,
        mq_hist_all_variants_bin_edges=mq_hist_all_variants.bin_edges,
    )

    tlod_hist_all_variants = input_mt.aggregate_rows(
        hl.agg.hist(input_mt.tlod_mean, 0, 40000, 40)
    )
    input_mt = input_mt.annotate_globals(
        tlod_hist_all_variants_bin_freq=tlod_hist_all_variants.bin_freq,
        tlod_hist_all_variants_n_larger=tlod_hist_all_variants.n_larger,
        tlod_hist_all_variants_bin_edges=tlod_hist_all_variants.bin_edges,
    )

    # Generate histogram for overall age distribution
    age_hist_all_samples = input_mt.aggregate_cols(
        hl.agg.hist(input_mt.age, 30, 80, 10)
    )
    input_mt = input_mt.annotate_globals(
        age_hist_all_samples_bin_freq=age_hist_all_samples.bin_freq,
        age_hist_all_samples_n_larger=age_hist_all_samples.n_larger,
        age_hist_all_samples_n_smaller=age_hist_all_samples.n_smaller,
        age_hist_all_samples_bin_edges=age_hist_all_samples.bin_edges,
    )

    # Add age histograms per variant type (heteroplasmic or homoplasmic)
    age_data = age_hists_expr(True, input_mt.GT, input_mt.age)
    input_mt = input_mt.annotate_rows(
        age_hist_hom=age_data.age_hist_hom, age_hist_het=age_data.age_hist_het
    )

    return input_mt


def add_annotations_by_hap_and_pop(input_mt: hl.MatrixTable) -> hl.MatrixTable:
    """
    Add variant annotations (such as AC, AN, AF, heteroplasmy histogram, and filtering allele frequency) split by haplogroup and population.

    :param input_mt: MatrixTable
    :return: MatrixTable with variant annotations
    """
    # Order the haplogroup-specific annotations
    list_hap_order = list(set(input_mt.hap.collect()))
    input_mt = input_mt.annotate_globals(hap_order=sorted(list_hap_order))

    # Sanity check for haplogroups (make sure that they at least start with a letter)
    for i in list_hap_order:
        if not re.match("^[A-Z]", i):
            sys.exit(f"Invalid haplogroup {i}, does not start with a letter")

    pre_hap_annotation_labels = [
        "pre_hap_AC",
        "pre_hap_AN",
        "pre_hap_AF",
        "pre_hap_AC_het",
        "pre_hap_AC_hom",
        "pre_hap_AF_hom",
        "pre_hap_AF_het",
        "pre_hap_hl_hist",
        "pre_hap_faf",
        "pre_hap_faf_hom",
    ]

    for i in pre_hap_annotation_labels:
        final_annotation = re.sub(
            "pre_", "", i
        )  # remove "pre" prefix for final annotations
        input_mt = input_mt.annotate_rows(
            **{final_annotation: standardize_haps(input_mt, i, sorted(list_hap_order))}
        )

    # Get a list of indexes where AC of the haplogroup is greater than 0, then get the list of haplogroups with that index
    input_mt = input_mt.annotate_rows(
        alt_haps=hl.enumerate(input_mt.hap_AC)
        .filter(lambda x: x[1] > 0)
        .map(lambda x: input_mt.hap_order[x[0]])
    )
    # Count number of haplogroups containing an alt allele
    input_mt = input_mt.annotate_rows(n_alt_haps=hl.len(input_mt.alt_haps))

    # Calculate hapmax
    input_mt = input_mt.annotate_rows(
        hapmax_AF_hom=input_mt.hap_order[(hl.argmax(input_mt.hap_AF_hom, unique=True))],
        hapmax_AF_het=input_mt.hap_order[(hl.argmax(input_mt.hap_AF_het, unique=True))],
    )

    # Calculate faf hapmax
    input_mt = input_mt.annotate_rows(
        faf_hapmax=hl.max(input_mt.hap_faf), faf_hapmax_hom=hl.max(input_mt.hap_faf_hom)
    )

    # Add populatation annotations
    found_pops = set(input_mt.pop.collect())
    # Order according to POPS
    final_pops = [x for x in POPS if x in found_pops]

    if len(found_pops - set(POPS)) > 0:
        sys.exit(f"Invalid population found")
    input_mt = input_mt.annotate_globals(pop_order=final_pops)

    pre_pop_annotation_labels = [
        "pre_pop_AN",
        "pre_pop_AC_het",
        "pre_pop_AC_hom",
        "pre_pop_AF_hom",
        "pre_pop_AF_het",
        "pre_pop_hl_hist",
    ]

    for i in pre_pop_annotation_labels:
        # Remove "pre" prefix for final annotations
        final_annotation = re.sub("pre_", "", i)
        input_mt = input_mt.annotate_rows(
            **{final_annotation: standardize_pops(input_mt, i, final_pops)}
        )

    # Drop intermediate annotations
    annotations_to_drop = [
        "pre_hap_AC",
        "pre_hap_AN",
        "pre_hap_AF",
        "pre_hap_AC_het",
        "pre_hap_AC_hom",
        "pre_hap_AF_hom",
        "pre_hap_AF_het",
        "pre_hap_hl_hist",
        "pre_hap_faf",
        "pre_hap_faf_hom",
        "AC_mid_het",
        "AF_mid_het",
        "pre_pop_AN",
        "pre_pop_AC_het",
        "pre_pop_AC_hom",
        "pre_pop_AF_hom",
        "pre_pop_AF_het",
        "pre_pop_hl_hist",
    ]

    input_mt = input_mt.drop(*annotations_to_drop)
    # Last-minute drops (ever add back in?)
    input_mt = input_mt.drop(
        "AC",
        "AF",
        "hap_AC",
        "hap_AF",
        "hap_faf",
        "faf_hapmax",
        "alt_haps",
        "n_alt_haps",
    )

    input_mt = input_mt.annotate_rows(
        filters=hl.if_else(
            input_mt.filters == {"PASS"}, hl.empty_set(hl.tstr), input_mt.filters
        )
    )

    return input_mt


def apply_common_low_het_flag(input_mt: hl.MatrixTable) -> hl.MatrixTable:
    """
    Apply the common_low_heteroplasmy flag to the MatrixTable.

    The common_low_heteroplasmy flag marks variants where the overall frequency is > 0.001 for samples with a heteroplasmy level > 0 and < 0.50 and either "low_allele_frac" or "PASS" for the genotype filter

    NOTE: The "low_allele_frac" is applied by Mutect2 to variants with a heteroplasmy level below the supplied vaf_filter_threshold

    :param input_mt: MatrixTable
    :return: MatrixTable with the common_low_heteroplasmy flag added
    """
    input_mt = input_mt.annotate_rows(
        AC_mid_het=hl.agg.count_where(
            (input_mt.HL < 0.50)
            & (input_mt.HL > 0.0)
            & ((input_mt.FT == {"PASS"}) | (input_mt.FT == {"low_allele_frac"}))
        )
    )
    input_mt = input_mt.annotate_rows(
        AF_mid_het=input_mt.AC_mid_het
        / hl.agg.count_where(
            hl.is_defined(input_mt.HL)
            & ((input_mt.FT == {"PASS"}) | (input_mt.FT == {"low_allele_frac"}))
        )
    )
    input_mt = input_mt.annotate_rows(
        common_low_heteroplasmy=input_mt.AF_mid_het > 0.001
    )

    return input_mt


def remove_low_allele_frac_genotypes(
    input_mt: hl.MatrixTable, vaf_filter_threshold: float = 0.01
) -> hl.MatrixTable:
    """
    Remove low_allele_frac genotypes and sets the call to homoplasmic reference.

    NOTE: vaf_filter_threshold should match what was supplied to the vaf_filter_threshold when running Mutect2, variants below this value will be set to homoplasmic reference after calculating the common_low_heteroplasmy filter, Mutect2 will have flagged these variants as "low_allele_frac"

    :param input_mt: MatrixTable
    :param vaf_filter_threshold: Should match vaf_filter_threshold supplied to Mutect2, variants below this value will be set to homoplasmic reference after calculating the common_low_heteroplasmy filter
    :return: MatrixTable with genotypes below the vaf_filter_threshold set to homoplasmic reference
    """
    # Set HL to 0 if < vaf_filter_threshold and remove variants that no longer have at least one alt call
    input_mt = input_mt.annotate_entries(
        HL=hl.if_else(
            (input_mt.HL > 0) & (input_mt.HL < vaf_filter_threshold), 0, input_mt.HL
        )
    )
    # Filter field for all variants with a heteroplasmy of 0 should be set to PASS
    # This step is needed to prevent homref calls that are filtered
    input_mt = input_mt.annotate_entries(
        FT=hl.if_else(input_mt.HL < vaf_filter_threshold, {"PASS"}, input_mt.FT)
    )
    input_mt = input_mt.annotate_entries(
        GT=hl.if_else(
            input_mt.HL < vaf_filter_threshold, hl.parse_call("0/0"), input_mt.GT
        )
    )

    # Check that variants no longer contain the "low_allele_frac" filter (vaf_filter_threshold should be set to appropriate level to remove these variants)
    laf_rows = input_mt.filter_rows(
        hl.agg.any(hl.str(input_mt.FT).contains("low_allele_frac"))
    )
    n_laf_rows = laf_rows.count_rows()
    if n_laf_rows > 0:
        sys.exit(
            "low_allele_frac filter should no longer be present after applying vaf_filter_threshold (vaf_filter_threshold should equal the vaf_filter_threshold supplied to Mutect2)"
        )
    input_mt = input_mt.filter_rows(hl.agg.any(input_mt.HL > 0))

    return input_mt


def apply_indel_stack_filter(input_mt: hl.MatrixTable) -> hl.MatrixTable:
    """
    Apply the indel_stack filter to the MatrixTable.

    The indel_stack filter marks alleles where all samples with the variant call had at least 2 different indels called at the position

    :param input_mt: MatrixTable
    :return: MatrixTable with the indel_stack filter added
    """
    # Add variant-level indel_stack at any indel allele where all samples with a variant call had at least 2 different indels called at that position
    # If any sample had a solo indel at that position, do not filter
    indel_expr = get_indel_expr(input_mt)
    input_mt = input_mt.annotate_cols(
        indel_pos_counter=hl.agg.filter(
            indel_expr, hl.agg.counter(input_mt.locus.position)
        )
    )
    indel_expr = get_indel_expr(input_mt)
    input_mt = input_mt.annotate_entries(
        indel_occurences=(
            hl.case()
            .when(
                (
                    indel_expr
                    & (input_mt.indel_pos_counter.get(input_mt.locus.position) >= 2)
                ),
                "stack",
            )
            .when(
                (
                    indel_expr
                    & (input_mt.indel_pos_counter.get(input_mt.locus.position) == 1)
                ),
                "solo",
            )
            .or_missing()
        )
    )

    # If stack is true and solo is false, the indel is stack only and should be filtered out
    input_mt = input_mt.annotate_rows(
        filters=hl.if_else(
            hl.agg.any(input_mt.indel_occurences == "stack")
            & ~hl.agg.any(input_mt.indel_occurences == "solo"),
            input_mt.filters.add("indel_stack"),
            input_mt.filters,
        )
    )

    return input_mt


def filter_genotypes_below_min_het_threshold(
    input_mt: hl.MatrixTable, min_het_threshold: float = 0.10
) -> hl.MatrixTable:
    """
    Filter out genotypes with a heteroplasmy below the min_het_threshold.

    This filter is a genotype level filter to remove variants with a heteroplasmy level below the specified min_het_threshold
    NOTE: Should later parameterize this function to allow other heteroplasmy cutoffs?

    :param input_mt: MatrixTable
    :param min_het_threshold: Minimum heteroplasmy level to define a variant as a PASS heteroplasmic variant, genotypes below this threshold will count towards the heteroplasmy_below_min_het_threshold filter and be set to missing
    :return: MatrixTable with the heteroplasmy_below_min_het_threshold in the FT field added where applicable
    """
    input_mt = input_mt.annotate_entries(
        FT=hl.if_else(
            (input_mt.HL < min_het_threshold) & (input_mt.GT.is_het()),
            input_mt.FT.add("heteroplasmy_below_min_het_threshold"),
            input_mt.FT,
        )
    )

    # Remove "PASS" from FT if it's not the only filter
    input_mt = input_mt.annotate_entries(
        FT=hl.if_else(input_mt.FT != {"PASS"}, input_mt.FT.remove("PASS"), input_mt.FT)
    )

    return input_mt


def apply_npg_filter(input_mt: hl.MatrixTable) -> hl.MatrixTable:
    """
    Apply the npg filter to the MatrixTable.

    The npg (no pass genotypes) filter marks sites that don't have at least one pass alt call

    :param input_mt: MatrixTable
    :return: MatrixTable with the npg filter added
    """
    input_mt = input_mt.annotate_rows(
        filters=hl.if_else(
            ~(hl.agg.any((input_mt.HL > 0.0) & (input_mt.FT == {"PASS"}))),
            input_mt.filters.add("npg"),
            input_mt.filters,
        )
    )

    return input_mt


def generate_filter_histogram(
    input_mt: hl.MatrixTable, filter_name: str
) -> hl.ArrayExpression:
    """
    Generate histogram for number of indiviudals with the specified sample-level filter at different heteroplasmy levels.

    :param input_mt: MatrixTable
    :param filter_name: Name of sample-filter for which to generate a histogram
    :return: Histogram containing the counts of individuals with a variant filtered by the specified filter name across binned heteroplasmy levels
    """
    filter_histogram = hl.agg.filter(
        hl.str(input_mt.FT).contains(filter_name), hl.agg.hist(input_mt.HL, 0, 1, 10)
    ).bin_freq

    return filter_histogram


def add_filter_annotations(
    input_mt: hl.MatrixTable,
    vaf_filter_threshold: float = 0.01,
    min_het_threshold: float = 0.10,
) -> hl.MatrixTable:
    """
    Generate histogram for number of individuals with the specified sample-level filter at different heteroplasmy levels.

    :param input_mt: MatrixTable
    :param vaf_filter_threshold: Should match vaf_filter_threshold supplied to Mutect2, variants below this value will be set to homoplasmic reference after calculating the common_low_heteroplasmy filter
    :param min_het_threshold: Minimum heteroplasmy level to define a variant as a PASS heteroplasmic variant, genotypes below this threshold will count towards the heteroplasmy_below_min_het_threshold filter and be set to missing
    :return: MatrixTable with added annotations for sample and variant level filters and number of genotypes with heteroplasmy_below_min_het_threshold
    """
    # TODO: pull these from header instead?
    filters = [
        "base_qual",
        "position",
        "strand_bias",
        "weak_evidence",
        "contamination",
        "heteroplasmy_below_min_het_threshold",
    ]

    logger.info("Applying common low heteroplasmy flag...")
    input_mt = apply_common_low_het_flag(input_mt)

    logger.info("Removing low_allele_frac genotypes...")
    input_mt = remove_low_allele_frac_genotypes(input_mt, vaf_filter_threshold)

    logger.info("Applying indel_stack filter...")
    input_mt = apply_indel_stack_filter(input_mt)

    logger.info(
        "Filtering genotypes below with heteroplasmy below the min_het_threshold..."
    )
    input_mt = filter_genotypes_below_min_het_threshold(input_mt, min_het_threshold)
    n_het_below_min_het_threshold = input_mt.aggregate_entries(
        hl.agg.count_where(
            hl.str(input_mt.FT).contains("heteroplasmy_below_min_het_threshold")
        )
    )

    logger.info("Applying npg filter...")
    input_mt = apply_npg_filter(input_mt)

    logger.info("Generating filter histograms and calculating excluded_AC...")
    for i in filters:
        annotation_name = i + "_hist"
        input_mt = input_mt.annotate_rows(
            **{annotation_name: generate_filter_histogram(input_mt, i)}
        )
    input_mt = input_mt.annotate_rows(
        excluded_AC=hl.agg.count_where(input_mt.FT != {"PASS"})
    )

    # Remove "PASS" from filters column if it's not the only filter
    input_mt = input_mt.annotate_rows(
        filters=hl.if_else(
            input_mt.filters != {"PASS"},
            input_mt.filters.remove("PASS"),
            input_mt.filters,
        )
    )

    return input_mt, n_het_below_min_het_threshold


def filter_genotypes(input_mt: hl.MatrixTable) -> hl.MatrixTable:
    """
    Set all genotype field values to missing if the variant is not "PASS" for that sample.

    :param input_mt: MatrixTable
    :return: MatrixTable with filtered genotype fields set to missing
    """
    pass_expr = input_mt.FT == {"PASS"}

    input_mt = input_mt.annotate_entries(
        GT=hl.or_missing(pass_expr, input_mt.GT),
        DP=hl.or_missing(pass_expr, input_mt.DP),
        HL=hl.or_missing(pass_expr, input_mt.HL),
        FT=hl.or_missing(pass_expr, input_mt.FT),
        MQ=hl.or_missing(pass_expr, input_mt.MQ),
        TLOD=hl.or_missing(pass_expr, input_mt.TLOD),
    )

    return input_mt


def add_sample_annotations(
    input_mt: hl.MatrixTable, min_hom_threshold: float = 0.95
) -> hl.MatrixTable:
    """
    Add sample annotations to the MatrixTable.

    These sample annotations include the callrate, number of heteroplasmic/homoplasmic SNPs/indels, and the number of singletons.
    Filtered variants (such as artifact_prone_site, npg, and indel_stack) are excluded from these calculations.

    :param input_mt: MatrixTable
    :param min_hom_threshold: Minimum heteroplasmy level to define a variant as homoplasmic
    :return: MatrixTable with sample annotations added
    """
    # Count number of variants
    num_rows = input_mt.count_rows()

    # Add sample qc annotations
    filter_expr = hl.len(input_mt.filters) == 0
    input_mt = input_mt.annotate_cols(
        callrate=hl.agg.filter(
            filter_expr, (hl.agg.count_where(hl.is_defined(input_mt.HL))) / num_rows
        ),
        n_singletons_het=hl.agg.filter(
            filter_expr,
            hl.agg.count_where(
                (input_mt.AC_het == 1)
                & ((input_mt.HL < min_hom_threshold) & (input_mt.HL > 0.0))
            ),
        ),
        n_singletons_hom=hl.agg.filter(
            filter_expr,
            hl.agg.count_where(
                (input_mt.AC_hom == 1) & (input_mt.HL >= min_hom_threshold)
            ),
        ),
        n_snp_het=hl.agg.filter(
            filter_expr,
            hl.agg.count_where(
                (input_mt.HL < min_hom_threshold)
                & (input_mt.HL > 0.0)
                & hl.is_snp(input_mt.alleles[0], input_mt.alleles[1])
            ),
        ),
        n_snp_hom=hl.agg.filter(
            filter_expr,
            hl.agg.count_where(
                (input_mt.HL >= min_hom_threshold)
                & hl.is_snp(input_mt.alleles[0], input_mt.alleles[1])
            ),
        ),
        n_indel_het=hl.agg.filter(
            filter_expr,
            hl.agg.count_where(
                (input_mt.HL < min_hom_threshold)
                & (input_mt.HL > 0.0)
                & (~hl.is_snp(input_mt.alleles[0], input_mt.alleles[1]))
            ),
        ),
        n_indel_hom=hl.agg.filter(
            filter_expr,
            hl.agg.count_where(
                (input_mt.HL >= min_hom_threshold)
                & (~hl.is_snp(input_mt.alleles[0], input_mt.alleles[1]))
            ),
        ),
    )

    return input_mt


def add_vep(input_mt: hl.MatrixTable, run_vep: bool, vep_output: str) -> hl.MatrixTable:
    """
    Add vep annotations to the MatrixTable.

    :param input_mt: MatrixTable
    :param run_vep: Whether or not to run vep
    :param vep_output: Path to the MatrixTable output vep results (either the existing results or where to ouput new vep results)
    :return: MatrixTable with vep annotations
    """
    if run_vep:
        vep_mt = hl.vep(input_mt)
        vep_mt = vep_mt.checkpoint(vep_output, overwrite=True)
    else:
        vep_mt = hl.read_matrix_table(vep_output)

    input_mt = input_mt.annotate_rows(
        vep=vep_mt.index_rows(input_mt.locus, input_mt.alleles).vep
    )
    # TODO: get vep version directly from config file
    input_mt = input_mt.annotate_globals(vep_version="v101")

    # If only filter is END_TRUNC, change lof for LC to HC and remove the END_TRUNC filter
    # Remove SINGLE_EXON flags because all exons are single exon in the mitochondria
    input_mt = input_mt.annotate_rows(
        vep=input_mt.vep.annotate(
            transcript_consequences=input_mt.vep.transcript_consequences.map(
                lambda x: x.annotate(
                    lof=hl.if_else(x.lof_filter == "END_TRUNC", "HC", x.lof),
                    lof_filter=hl.if_else(
                        x.lof_filter == "END_TRUNC", hl.missing(hl.tstr), x.lof_filter
                    ),
                    lof_flags=hl.if_else(
                        x.lof_flags == "SINGLE_EXON", hl.missing(hl.tstr), x.lof_flags
                    ),
                )
            )
        )
    )

    end_trunc_count = input_mt.filter_rows(
        hl.str(input_mt.vep.transcript_consequences[0].lof_filter).contains("END_TRUNC")
    ).count_rows()
    if end_trunc_count > 0:
        sys.exit(
            f"END_TRUNC filter should no longer be present but was found for {end_trunc_count} variants"
        )

    single_exon_count = input_mt.filter_rows(
        hl.str(input_mt.vep.transcript_consequences[0].lof_flags).contains(
            "SINGLE_EXON"
        )
    ).count_rows()
    if single_exon_count > 0:
        sys.exit(
            f"SINGLE_EXON flag should no longer be present but was found for {single_exon_count} variants"
        )

    return input_mt


def add_rsids(input_mt: hl.MatrixTable) -> hl.MatrixTable:
    """
    Add rsid annotations to the MatrixTable.

    :param input_mt: MatrixTable
    :return: MatrixTable with rsid annotations added
    """
    dbsnp_import_args = dbsnp.versions["b154"].import_args
    # Replace the contig recoding with just the chrM mapping
    dbsnp_import_args.update({"contig_recoding": {"NC_012920.1": "chrM"}})
    dbsnp_ht = _import_dbsnp(**dbsnp_import_args)

    input_mt = input_mt.annotate_rows(
        rsid=dbsnp_ht[input_mt.locus, input_mt.alleles].rsid
    )
    input_mt = input_mt.annotate_globals(dbsnp_version="b154")

    return input_mt


def export_simplified_variants(input_ht: hl.Table, output_dir: str) -> None:
    """
    Export a text file containing only several high-level variant annotations.

    :param input_ht: Hail Table of variants
    :param output_dir: Output directory to which results should be output
    :return: None
    """
    reduced_ht = (
        input_ht.key_by(
            chromosome=input_ht.locus.contig,
            position=input_ht.locus.position,
            ref=input_ht.alleles[0],
            alt=input_ht.alleles[1],
        )
        .select("filters", "AC_hom", "AC_het", "AF_hom", "AF_het", "AN", "max_hl")
        .rename({"max_hl": "max_observed_heteroplasmy"})
    )
    reduced_ht = reduced_ht.annotate(
        filters=hl.if_else(
            hl.len(reduced_ht.filters) == 0,
            "PASS",
            hl.str(",").join(hl.array(reduced_ht.filters)),
        )
    )

    reduced_ht.export(f"{output_dir}/reduced_annotations.txt")


def generate_output_paths(
    output_dir: str, file_name: str, subset_name: str, extension: str
) -> list:
    """
    Generate output paths for results files based on the given output directory, file name, subset name, and extension.

    :param output_dir: Output directory to which results should be output
    :param file_name: Name of the file, preceeds subset_name
    :param subset_name: Name that should be appended to output file names
    :param extension: Extension for the output file
    :return: Path for the file
    """
    # set up output paths for callset
    file_path = f"{output_dir}/{file_name}{subset_name}.{extension}"

    return file_path


def report_stats(
    input_mt: hl.MatrixTable,
    output_dir: str,
    pass_only: bool,
    n_samples_below_cn: int,
    n_samples_above_cn: int,
    n_samples_contam: int,
    n_het_below_min_het_threshold: int,
    min_het_threshold: float = 0.10,
    min_hom_threshold: float = 0.95,
) -> None:
    """
    Generate output report with basic stats.

    :param input_mt: MatrixTable
    :param output_dir: Output directory to which results should be output
    :param pass_only: Whether or not directory should be filtered to pass_only variants
    :param n_samples_below_cn: Number of samples removed because mitochondrial number is less than 50
    :param n_samples_above_cn: Number of samples removed because mitochondrial number is above 500
    :param n_samples_contam: Number of samples removed because of contamination
    :param n_het_below_min_het_threshold: Number of genotypes filtered because the heteroplasmy levels was below the min_het_threshold
    :param min_het_threshold: Minimum heteroplasmy level to define a variant as a PASS heteroplasmic variant, genotypes below this threshold will count towards the heteroplasmy_below_min_het_threshold filter and be set to missing
    :param min_hom_threshold: Minimum heteroplasmy level to define a variant as homoplasmic
    :return: None
    """
    if pass_only:
        suffix = "_pass"
        input_mt = input_mt.filter_rows(hl.len(input_mt.filters) == 0)
    else:
        suffix = ""
    out_stats = hl.hadoop_open(f"{output_dir}/stats{suffix}.txt", "w")

    if pass_only:
        out_stats.write("Below metrics are for PASS-only variants\n\n")

    # Report numbers of filtered samples/genotypes
    out_stats.write(
        f"Number of samples removed because contamination above 2%: {n_samples_contam}\n"
    )
    out_stats.write(
        f"Number of samples removed because mitochondrial copy number below 50: {n_samples_below_cn}\n"
    )
    out_stats.write(
        f"Number of samples removed because mitochondrial copy number above 500: {n_samples_above_cn}\n"
    )
    out_stats.write(
        f'Number of genotypes filtered because "heteroplasmy_below_min_het_threshold": {n_het_below_min_het_threshold}\n\n'
    )

    # Count variant, samples, bases
    unique_variants, samples = input_mt.count()
    out_stats.write(f"Number of samples: {samples}\n")
    out_stats.write(f"Number of unique variants: {unique_variants}\n")
    bases_w_variant = len(set(input_mt.locus.position.collect()))
    out_stats.write(f"Number of bases with variation: {bases_w_variant}\n\n")

    # Count number of filters
    for filter_name, filter_count in Counter(
        [i for sublist in input_mt.filters.collect() for i in sublist]
    ).items():
        out_stats.write(
            f'Number of variants with "{filter_name}" filter: {filter_count} variants\n'
        )

    # Calculate row stats
    row_stats = input_mt.aggregate_rows(
        hl.struct(
            common_low_het_count=hl.agg.count_where(input_mt.common_low_heteroplasmy),
            het_only_sites=hl.agg.count_where(
                (input_mt.AC_het > 0) & (input_mt.AC_hom == 0)
            ),
            hom_only_sites=hl.agg.count_where(
                (input_mt.AC_hom > 0) & (input_mt.AC_het == 0)
            ),
            het_and_hom_sites=hl.agg.count_where(
                (input_mt.AC_hom > 0) & (input_mt.AC_het > 0)
            ),
            hap_defining_sites=hl.agg.count_where(input_mt.hap_defining_variant),
            snps=hl.agg.count_where(
                hl.is_snp(input_mt.alleles[0], input_mt.alleles[1])
            ),
            indels=hl.agg.count_where(
                hl.is_indel(input_mt.alleles[0], input_mt.alleles[1])
            ),
            transitions=hl.agg.count_where(
                hl.is_transition(input_mt.alleles[0], input_mt.alleles[1])
            ),
            transversions=hl.agg.count_where(
                hl.is_transversion(input_mt.alleles[0], input_mt.alleles[1])
            ),
        )
    )

    # Calculate col stats
    col_stats = input_mt.aggregate_cols(
        hl.struct(
            unique_haplogroups=hl.len(hl.agg.collect_as_set(input_mt.major_haplogroup)),
            unique_top_level_haplogroups=hl.len(hl.agg.collect_as_set(input_mt.hap)),
        )
    )

    # Calculate entry stats
    entry_stats = input_mt.aggregate_entries(
        hl.struct(
            total_variants=hl.agg.count_where(input_mt.HL > 0),
            total_hom_variants=hl.agg.count_where(input_mt.HL >= min_hom_threshold),
            total_het_variants=hl.agg.count_where(
                (input_mt.HL < min_hom_threshold) & (input_mt.HL >= min_het_threshold)
            ),
            min_hl=hl.agg.filter(input_mt.HL > 0, hl.agg.min(input_mt.HL)),
            max_hl=hl.agg.filter(input_mt.HL > 0, hl.agg.max(input_mt.HL)),
        )
    )

    # Count number of flags
    out_stats.write(
        f'Number of variants with "common_low_heteroplasmy" flag: {row_stats["common_low_het_count"]} variants\n\n'
    )

    # Count variants
    out_stats.write(f'Total number of variants: {entry_stats["total_variants"]}\n')

    # Count of homoplasmic/heteroplasmic variants
    out_stats.write(
        f'Number of homoplasmic-only sites: {row_stats["hom_only_sites"]}\n'
    )
    out_stats.write(
        f'Number of heteroplasmic-only sites: {row_stats["het_only_sites"]}\n'
    )
    out_stats.write(f'Number of het and hom sites: {row_stats["het_and_hom_sites"]}\n')

    percent_hom = round(
        entry_stats["total_hom_variants"] / entry_stats["total_variants"], 2
    )
    percent_het = round(
        entry_stats["total_het_variants"] / entry_stats["total_variants"], 2
    )
    out_stats.write(
        f'Total number of homoplasmic variants: {entry_stats["total_hom_variants"]}\n'
    )
    out_stats.write(f"Percent homoplasmic variants: {percent_hom}\n")
    out_stats.write(
        f'Total number of heteroplasmic variants: {entry_stats["total_het_variants"]}\n'
    )
    out_stats.write(f"Percent heteroplasmic variants: {percent_het}\n\n")

    out_stats.write(f'Minimum heteroplasmy detected: {entry_stats["min_hl"]}\n')
    out_stats.write(f'Maximum heteroplasmy detected: {entry_stats["max_hl"]}\n\n')

    # Count number of snps and indels
    out_stats.write(f'Number of SNPs: {row_stats["snps"]}\n')
    out_stats.write(f'Number of indels: {row_stats["indels"]}\n')

    # Count number of transitions and transversions
    out_stats.write(f'Number of transitions: {row_stats["transitions"]}\n')
    out_stats.write(f'Number of transversions: {row_stats["transversions"]}\n')
    out_stats.write(
        f'Number of haplogroup defining variants: {row_stats["hap_defining_sites"]}\n\n'
    )

    # Count number of haplogroups
    out_stats.write(
        f'Number of unique haplogroups: {col_stats["unique_haplogroups"]}\n'
    )
    out_stats.write(
        f'Number of top-level haplogroups: {col_stats["unique_top_level_haplogroups"]}\n'
    )

    out_stats.close()


def change_to_grch38_chrm(input_mt: hl.MatrixTable) -> None:
    """
    Change build to GRCh38 and filters reference genome to chrM.

    :param input_mt: MatrixTable
    :return: MatrixTable with GRCh38 reference genome subsetted to just chrM (so that extraneous contigs will be excluded from VCF output)
    """
    ref = hl.get_reference("GRCh38")
    my_ref = hl.ReferenceGenome(
        "GRCh38_chrM", contigs=["chrM"], lengths={"chrM": ref.lengths["chrM"]}
    )
    assert "chrM" in ref.contigs
    input_mt = input_mt.key_rows_by(
        locus=hl.locus("chrM", input_mt.locus.position, reference_genome="GRCh38_chrM"),
        alleles=input_mt.alleles,
    )

    return input_mt


def format_vcf(
    input_mt: hl.MatrixTable,
    output_dir: str,
    min_hom_threshold: float = 0.95,
    vaf_filter_threshold: float = 0.01,
    min_het_threshold: float = 0.10,
) -> dict:
    """
    Generate dictionary for VCF header annotations.

    :param input_mt: MatrixTable
    :param min_hom_threshold: Minimum heteroplasmy level to define a variant as homoplasmic
    :param vaf_filter_threshold: Should match vaf_filter_threshold supplied to Mutect2, variants below this value will be set to homoplasmic reference after calculating the common_low_heteroplasmy filter
    :param min_het_threshold: Minimum heteroplasmy level to define a variant as a PASS heteroplasmic variant, genotypes below this threshold will count towards the heteroplasmy_below_min_het_threshold filter and be set to missing
    :param output_dir: Output directory to which appended header info should be written
    :return: MatrixTable with VCF annotations in the info field and dictionary of filter, info, and format fields to be output in the VCF header; path of VCF headers to append
    """
    input_mt = change_to_grch38_chrm(input_mt)

    haplogroup_order = hl.eval(input_mt.hap_order)
    population_order = hl.eval(input_mt.pop_order)

    age_hist_hom_bin_edges = input_mt.age_hist_hom.bin_edges.take(1)[0]
    age_hist_het_bin_edges = input_mt.age_hist_het.bin_edges.take(1)[0]
    hl_hist_bin_edges = input_mt.hl_hist.bin_edges.take(1)[0]
    dp_hist_all_bin_edges = input_mt.dp_hist_all.bin_edges.take(1)[0]
    dp_hist_alt_bin_edges = input_mt.dp_hist_alt.bin_edges.take(1)[0]

    input_mt = input_mt.annotate_rows(
        hl_hist=input_mt.hl_hist.bin_freq,
        age_hist_hom_bin_freq=input_mt.age_hist_hom.bin_freq,
        age_hist_hom_n_smaller=input_mt.age_hist_hom.n_smaller,
        age_hist_hom_n_larger=input_mt.age_hist_hom.n_larger,
        age_hist_het_bin_freq=input_mt.age_hist_het.bin_freq,
        age_hist_het_n_smaller=input_mt.age_hist_het.n_smaller,
        age_hist_het_n_larger=input_mt.age_hist_het.n_larger,
        dp_hist_all_n_larger=input_mt.dp_hist_all.n_larger,
        dp_hist_alt_n_larger=input_mt.dp_hist_alt.n_larger,
        dp_hist_all_bin_freq=input_mt.dp_hist_all.bin_freq,
        dp_hist_alt_bin_freq=input_mt.dp_hist_alt.bin_freq,
    )

    input_mt = input_mt.annotate_rows(vep=vep_struct_to_csq(input_mt.vep))

    # Get length of annotations to use in Number fields in the VCF where necessary
    len_hap_hl_hist = len(input_mt.hap_hl_hist.take(1)[0])
    len_pop_hl_hist = len(input_mt.pop_hl_hist.take(1)[0])

    # Output appended header info to file
    vcf_header_file = output_dir + "/extra_fields_for_header.tsv"
    appended_vcf_header = dedent(
        f"""
    ##VEP version={hl.eval(input_mt.vep_version)}
    ##dbSNP version={hl.eval(input_mt.dbsnp_version)}
    ##age distributions=bin_edges:{hl.eval(input_mt.age_hist_all_samples_bin_edges)}, bin_freq:{hl.eval(input_mt.age_hist_all_samples_bin_freq)}, n_smaller:{hl.eval(input_mt.age_hist_all_samples_n_smaller)}, n_larger:{hl.eval(input_mt.age_hist_all_samples_n_larger)}

    """
    )
    with hl.hadoop_open(vcf_header_file, "w") as out:
        out.write(appended_vcf_header)

    # Drop intermediate annotations
    input_mt = input_mt.drop(
        "region",
        "variant_context",
        "age_hist_het",
        "age_hist_hom",
        "dp_hist_all",
        "dp_hist_alt",
    )

    ht = input_mt.rows()
    # Move row annotations into info struct
    input_mt = input_mt.annotate_rows(info=hl.struct())
    input_mt = input_mt.annotate_rows(
        info=input_mt.info.annotate(**ht[input_mt.row_key]).drop("rsid")
    ).select_rows(
        "rsid", "filters", "info"
    )  # create info annotation

    # Convert "rsid" array to str for VCF output
    input_mt = input_mt.annotate_rows(rsid=hl.str(";").join(input_mt.rsid))

    # Convert "," to "|" for array annotations
    for key, value in input_mt.row_value.info.items():
        if str(value).startswith("<Array"):
            if str(value.dtype).startswith("array<array"):
                # If value is an array of arrays, only replace the commas within each individual array
                input_mt = input_mt.annotate_rows(
                    info=input_mt.info.annotate(
                        **{
                            key: hl.map(
                                lambda x: hl.delimit(x, delimiter="|"),
                                input_mt.info[key],
                            )
                        }
                    )
                )
            else:
                input_mt = input_mt.annotate_rows(
                    info=input_mt.info.annotate(
                        **{key: hl.delimit(input_mt.info[key], delimiter="|")}
                    )
                )

    meta_dict = {
        "filter": {
            "artifact_prone_site": {
                "Description": "Variant overlaps site that is commonly reported in literature to be artifact prone"
            },
            "npg": {
                "Description": "No-pass-genotypes site (no individuals were PASS for the variant)"
            },
            "indel_stack": {
                "Description": "Allele where all samples with the variant call had at least 2 different heteroplasmic indels called at the position"
            },
        },
        "info": {
            "variant_collapsed": {
                "Description": "Variant in format of RefPosAlt",
                "Number": "1",
                "Type": "String",
            },
            "hap_defining_variant": {
                "Description": "Present if variant is present as a haplogroup defining variant in PhyloTree build 17",
                "Number": "0",
                "Type": "Flag",
            },
            "common_low_heteroplasmy": {
                "Description": f"Present if variant is found at an overall frequency of .001 across all samples with a heteroplasmy level > 0 and < 0.50 (includes variants <{vaf_filter_threshold} heteroplasmy which are subsequently filtered)",
                "Number": "0",
                "Type": "Flag",
            },
            "AN": {
                "Description": "Overall allele number (number of samples with non-missing genotype)",
                "Number": "1",
                "Type": "Integer",
            },
            "AC_hom": {
                "Description": f"Allele count restricted to variants with a heteroplasmy level >= {min_hom_threshold}",
                "Number": "1",
                "Type": "Integer",
            },  # should put in threshold variable
            "AC_het": {
                "Description": f"Allele count restricted to variants with a heteroplasmy level >= 0.10 and < {min_hom_threshold}",
                "Number": "1",
                "Type": "Integer",
            },
            "hl_hist": {
                "Description": f"Histogram of heteroplasmy levels; bin edges are: {hl_hist_bin_edges}",
                "Number": "1",
                "Type": "String",
            },
            "hap_hl_hist": {
                "Description": f"Histogram of heteroplasmy levels for each haplogroup; bin edges are: {hl_hist_bin_edges}, haplogroup order: {haplogroup_order}",
                "Number": f"{len_hap_hl_hist}",
                "Type": "String",
            },
            "AF_hom": {
                "Description": f"Allele frequency restricted to variants with a heteroplasmy level >= {min_hom_threshold}",
                "Number": "1",
                "Type": "Float",
            },
            "AF_het": {
                "Description": f"Allele frequency restricted to variants with a heteroplasmy level >= 0.10 and < {min_hom_threshold}",
                "Number": "1",
                "Type": "Float",
            },
            "max_hl": {
                "Description": "Maximum heteroplasmy level observed among all samples for that variant",
                "Number": "1",
                "Type": "Float",
            },
            "hap_AN": {
                "Description": f"List of overall allele number for each haplogroup, haplogroup order: {haplogroup_order}",
                "Number": "1",
                "Type": "String",
            },
            "hap_AC_het": {
                "Description": f"List of AC_het for each haplogroup, haplogroup order: {haplogroup_order}",
                "Number": "1",
                "Type": "String",
            },
            "hap_AC_hom": {
                "Description": f"List of AC_hom for each haplogroup, haplogroup order: {haplogroup_order}",
                "Number": "1",
                "Type": "String",
            },
            "hap_AF_hom": {
                "Description": f"List of AF_hom for each haplogroup, haplogroup order: {haplogroup_order}",
                "Number": "1",
                "Type": "String",
            },
            "hap_AF_het": {
                "Description": f"List of AF_het for each haplogroup, haplogroup order: {haplogroup_order}",
                "Number": "1",
                "Type": "String",
            },
            "hap_faf_hom": {
                "Description": f"List of filtering allele frequency for each haplogroup restricted to homoplasmic variants, haplogroup order: {haplogroup_order}",
                "Number": "1",
                "Type": "String",
            },
            "hapmax_AF_hom": {
                "Description": "Haplogroup with maximum AF_hom",
                "Number": "1",
                "Type": "String",
            },
            "hapmax_AF_het": {
                "Description": "Haplogroup with maximum AF_het",
                "Number": "1",
                "Type": "String",
            },
            "faf_hapmax_hom": {
                "Description": "Maximum filtering allele frequency across haplogroups restricted to homoplasmic variants",
                "Number": "1",
                "Type": "Float",
            },
            "bin_edges_hl_hist": {
                "Description": "Bin edges for histogram of heteroplasmy levels",
                "Number": "1",
                "Type": "String",
            },
            "pop_AN": {
                "Description": f"List of overall allele number for each population, population order: {population_order}",
                "Number": "1",
                "Type": "String",
            },
            "pop_AC_het": {
                "Description": f"List of AC_het for each population, population order: {population_order}",
                "Number": "1",
                "Type": "String",
            },
            "pop_AC_hom": {
                "Description": f"List of AC_hom for each population, population order: {population_order}",
                "Number": "1",
                "Type": "String",
            },
            "pop_AF_hom": {
                "Description": f"List of AF_hom for each population, population order: {population_order}",
                "Number": "1",
                "Type": "String",
            },
            "pop_AF_het": {
                "Description": f"List of AF_het for each population, population order: {population_order}",
                "Number": "1",
                "Type": "String",
            },
            "pop_hl_hist": {
                "Description": f"Histogram of heteroplasmy levels for each population; bin edges are: {hl_hist_bin_edges}, population order: {population_order}",
                "Number": f"{len_pop_hl_hist}",
                "Type": "String",
            },
            "age_hist_hom_bin_freq": {
                "Description": f"Histogram of ages of individuals with a homoplasmic variant; bin edges are: {age_hist_hom_bin_edges}",
                "Number": "1",
                "Type": "String",
            },
            "age_hist_hom_n_smaller": {
                "Description": "Count of age values falling below lowest histogram bin edge for individuals with a homoplasmic variant",
                "Number": "1",
                "Type": "String",
            },
            "age_hist_hom_n_larger": {
                "Description": "Count of age values falling above highest histogram bin edge for individuals with a homoplasmic variant",
                "Number": "1",
                "Type": "String",
            },
            "age_hist_het_bin_freq": {
                "Description": f"Histogram of ages of individuals with a heteroplasmic variant; bin edges are: {age_hist_het_bin_edges}",
                "Number": "1",
                "Type": "String",
            },
            "age_hist_het_n_smaller": {
                "Description": "Count of age values falling below lowest histogram bin edge for individuals with a heteroplasmic variant",
                "Number": "1",
                "Type": "String",
            },
            "age_hist_het_n_larger": {
                "Description": "Count of age values falling above highest histogram bin edge for individuals with a heteroplasmic variant",
                "Number": "1",
                "Type": "String",
            },
            "dp_hist_all_n_larger": {
                "Description": "Count of dp values falling above highest histogram bin edge for all individuals",
                "Number": "1",
                "Type": "String",
            },
            "dp_hist_alt_n_larger": {
                "Description": "Count of dp values falling above highest histogram bin edge for individuals with the alternative allele",
                "Number": "1",
                "Type": "String",
            },
            "dp_hist_all_bin_freq": {
                "Description": f"Histogram of dp values for all individuals; bin edges are: {dp_hist_all_bin_edges}",
                "Number": "1",
                "Type": "String",
            },
            "dp_hist_alt_bin_freq": {
                "Description": f"Histogram of dp values for individuals with the alternative allele; bin edges are: {dp_hist_alt_bin_edges}",
                "Number": "1",
                "Type": "String",
            },
            "dp_mean": {
                "Description": "Mean depth across all individuals for the site",
                "Number": "1",
                "Type": "Float",
            },
            "mq_mean": {
                "Description": "Mean MMQ (median mapping quality) across individuals with a variant for the site",
                "Number": "1",
                "Type": "Float",
            },
            "tlod_mean": {
                "Description": "Mean TLOD (Log 10 likelihood ratio score of variant existing versus not existing) across individuals with a variant for the site",
                "Number": "1",
                "Type": "Float",
            },
            "pon_mt_trna_prediction": {
                "Description": "tRNA pathogenicity classification from PON-mt-tRNA",
                "Number": "1",
                "Type": "String",
            },
            "pon_ml_probability_of_pathogenicity": {
                "Description": "tRNA ML_probability_of_pathogenicity from PON-mt-tRNA",
                "Number": "1",
                "Type": "Float",
            },
            "mitotip_score": {
                "Description": "MitoTip raw score",
                "Number": "1",
                "Type": "Float",
            },
            "mitotip_trna_prediction": {
                "Description": "MitoTip score interpretation",
                "Number": "1",
                "Type": "String",
            },
            "vep": {
                "Description": "Consequence annotations from Ensembl VEP; note that the SINGLE_EXON flag and END_TRUNC filters have been removed from the LOFTEE annotations to avoid misinterpretation in context of the mitochondrial genome. Format: Allele|Consequence|IMPACT|SYMBOL|Gene|Feature_type|Feature|BIOTYPE|EXON|INTRON|HGVSc|HGVSp|cDNA_position|CDS_position|Protein_position|Amino_acids|Codons|ALLELE_NUM|DISTANCE|STRAND|VARIANT_CLASS|MINIMISED|SYMBOL_SOURCE|HGNC_ID|CANONICAL|TSL|APPRIS|CCDS|ENSP|SWISSPROT|TREMBL|UNIPARC|GENE_PHENO|SIFT|PolyPhen|DOMAINS|HGVS_OFFSET|MOTIF_NAME|MOTIF_POS|HIGH_INF_POS|MOTIF_SCORE_CHANGE|LoF|LoF_filter|LoF_flags|LoF_info",
                "Number": ".",
                "Type": "String",
            },
            "filters": {
                "Description": "Site-level filters",
                "Number": ".",
                "Type": "String",
            },
            "base_qual_hist": {
                "Description": f"Histogram of number of individuals failing the base_qual filter (alternate allele median base quality) across heteroplasmy levels, bin edges are: {hl_hist_bin_edges}",
                "Number": "1",
                "Type": "String",
            },
            "heteroplasmy_below_min_het_threshold_hist": {
                "Description": f"Histogram of number of individuals with a heteroplasmy level below {min_het_threshold}, bin edges are: {hl_hist_bin_edges}",
                "Number": "1",
                "Type": "String",
            },
            "position_hist": {
                "Description": f"Histogram of number of individuals failing the position filter (median distance of alternate variants from end of reads) across heteroplasmy levels, bin edges are: {hl_hist_bin_edges}",
                "Number": "1",
                "Type": "String",
            },
            "strand_bias_hist": {
                "Description": f"Histogram of number of individuals failing the strand_bias filter (evidence for alternate allele comes from one read direction only) across heteroplasmy levels, bin edges are: {hl_hist_bin_edges}",
                "Number": "1",
                "Type": "String",
            },
            "weak_evidence_hist": {
                "Description": f"Histogram of number of individuals failing the weak_evidence filter (mutation does not meet likelihood threshold) across heteroplasmy levels, bin edges are: {hl_hist_bin_edges}",
                "Number": "1",
                "Type": "String",
            },
            "contamination_hist": {
                "Description": f"Histogram of number of individuals failing the contamination filter across heteroplasmy levels, bin edges are: {hl_hist_bin_edges}",
                "Number": "1",
                "Type": "String",
            },
            "excluded_AC": {
                "Description": "Excluded allele count (number of individuals in which the variant was filtered out)",
                "Number": "1",
                "Type": "String",
            },
        },
        "format": {
            "GT": {
                "Description": f"Genotype, 1/1 if heteroplasmy level >= {min_hom_threshold}, and 0/1 if heteroplasmy level < {min_hom_threshold}",
                "Number": "1",
                "Type": "String",
            },
            "DP": {
                "Description": "Depth of coverage",
                "Number": "1",
                "Type": "Integer",
            },
            "FT": {
                "Description": "Sample-level filters",
                "Number": ".",
                "Type": "String",
            },
            "HL": {"Description": "Heteroplasmy level", "Number": "1", "Type": "Float"},
            "MQ": {"Description": "Mapping quality", "Number": "1", "Type": "Float"},
            "TLOD": {
                "Description": "Log 10 likelihood ratio score of variant existing versus not existing",
                "Number": "1",
                "Type": "Float",
            },
        },
    }

    return input_mt, meta_dict, vcf_header_file


def main(args):  # noqa: D103
    mt_path = args.mt_path
    output_dir = args.output_dir
    participant_data = args.participant_data
    vep_results = args.vep_results
    min_hom_threshold = args.min_hom_threshold
    vaf_filter_threshold = args.vaf_filter_threshold
    min_het_threshold = args.min_het_threshold
    gnomad_subset = args.subset_to_gnomad_release
    keep_all_samples = args.keep_all_samples
    run_vep = args.run_vep

    logger.info("Cutoff for homoplasmic variants is set to %.2f...", min_hom_threshold)

    # Define mt path, output directory, subset name
    subset_name = ""

    logger.info("Adding genotype annotation...")
    mt = add_genotype(mt_path, min_hom_threshold)

    logger.info("Adding annotations from Terra...")
    mt = add_terra_metadata(mt, participant_data)

    logger.info("Annotating haplogroup-defining variants...")
    mt = add_hap_defining(mt)

    logger.info("Annotating tRNA predictions...")
    mt = add_trna_predictions(mt)

    # If 'subset-to-gnomad-release' is set, 'age' and 'pop' are added by the add_gnomad_metadata function.
    # If 'subset-to-gnomad-release' is not set, the user should include an 'age' and 'pop' column in the file supplied to `participant-data`.
    if gnomad_subset:
        logger.info("Adding gnomAD metadata sample annotations...")
        mt = add_gnomad_metadata(mt)
    else:
        logger.info("Adding age and pop annotations...")
        mt = add_age_and_pop(mt, participant_data)

    logger.info("Adding variant context annotations...")
    mt = add_variant_context(mt)

    # If specified, subet to only the gnomAD samples in the current release
    if gnomad_subset:
        logger.warn("Subsetting results to gnomAD release samples...")
        subset_name = "_gnomad"

        # Subset to release samples and filter out rows that no longer have at least one alt call
        mt = mt.filter_cols(mt.release)  # Filter to cols where release is true
        mt = mt.filter_rows(hl.agg.any(mt.HL > 0))

    logger.info("Checking for samples with low/high mitochondrial copy number...")
    mt, n_removed_below_cn, n_removed_above_cn = filter_by_copy_number(
        mt, keep_all_samples
    )

    logger.info("Checking for contaminated samples...")
    mt, n_contaminated = filter_by_contamination(mt, output_dir, keep_all_samples)

    logger.info("Switch build and checkpoint...")
    # Switch build 37 to build 38
    mt = mt.key_rows_by(
        locus=hl.locus("chrM", mt.locus.position, reference_genome="GRCh38"),
        alleles=mt.alleles,
    )
    mt = mt.checkpoint(f"{output_dir}/prior_to_vep.mt", overwrite=args.overwrite)

    logger.info("Adding vep annotations...")
    mt = add_vep(mt, run_vep, vep_results)

    logger.info("Adding dbsnp annotations...")
    mt = add_rsids(mt)

    logger.info("Setting up output paths...")
    annotated_mt_path = generate_output_paths(
        output_dir, "annotated_combined", subset_name, "mt"
    )
    sites_ht_path = generate_output_paths(
        output_dir, "combined_sites_only", subset_name, "ht"
    )
    sites_txt_path = generate_output_paths(
        output_dir, "combined_sites_only", subset_name, "txt"
    )
    sites_vcf_path = generate_output_paths(
        output_dir, "combined_sites_only", subset_name, "vcf.bgz"
    )
    samples_txt_path = generate_output_paths(
        output_dir, "sample_annotations", subset_name, "txt"
    )
    samples_vcf_path = generate_output_paths(
        output_dir, "sample_vcf", subset_name, "vcf.bgz"
    )

    logger.info("Results will be output to the following files:")
    print(
        "\n".join(
            [
                annotated_mt_path,
                sites_ht_path,
                sites_txt_path,
                sites_vcf_path,
                samples_txt_path,
                samples_vcf_path,
            ]
        )
    )

    logger.info("Annotating MT...")
    mt, n_het_below_min_het_threshold = add_filter_annotations(
        mt, vaf_filter_threshold, min_het_threshold
    )

    mt = mt.checkpoint(
        f"{output_dir}/prior_to_filter_genotypes.mt", overwrite=args.overwrite
    )

    mt = filter_genotypes(mt)
    # Add variant annotations such as AC, AF, and AN
    mt = mt.annotate_rows(**dict(generate_expressions(mt, min_hom_threshold)))
    # Checkpoint to help avoid Hail errors from large queries
    mt = mt.checkpoint(f"{output_dir}/temp.mt", overwrite=args.overwrite)
    mt = add_quality_histograms(mt)
    mt = add_annotations_by_hap_and_pop(mt)
    mt = add_descriptions(
        mt, min_hom_threshold, vaf_filter_threshold, min_het_threshold
    )
    mt = mt.checkpoint(
        annotated_mt_path, overwrite=args.overwrite
    )  # Full matrix table for internal use

    logger.info("Generating summary statistics reports...")
    report_stats(
        mt,
        output_dir,
        False,
        n_removed_below_cn,
        n_removed_above_cn,
        n_contaminated,
        n_het_below_min_het_threshold,
    )
    report_stats(
        mt,
        output_dir,
        True,
        n_removed_below_cn,
        n_removed_above_cn,
        n_contaminated,
        n_het_below_min_het_threshold,
    )

    logger.info("Writing ht...")
    variant_ht = mt.rows()
    variant_ht = variant_ht.drop("region", "variant_context")
    variant_ht = adjust_descriptions(variant_ht)
    variant_ht.export(sites_txt_path)  # Sites-only txt file for external use
    variant_ht.write(
        sites_ht_path, overwrite=args.overwrite
    )  # Sites-only ht for external use

    logger.info("Writing sample annotations...")
    mt = add_sample_annotations(mt, min_hom_threshold)
    sample_ht = mt.cols()
    sample_ht.group_by(sample_ht.hap).aggregate(n=hl.agg.count()).export(
        f"{output_dir}/haplogroup_counts.txt"
    )  # Counts of top level haplogroups
    sample_ht.export(samples_txt_path)  # Sample annotations txt file for internal use

    logger.info("Formatting and writing VCF...")
    rows_ht = mt.rows()
    export_simplified_variants(rows_ht, output_dir)
    vcf_mt, vcf_meta, vcf_header_file = format_vcf(mt, output_dir, min_hom_threshold)
    hl.export_vcf(
        vcf_mt,
        samples_vcf_path,
        metadata=vcf_meta,
        append_to_header=vcf_header_file,
        tabix=True,
    )  # Full VCF for internal use
    vcf_variant_ht = vcf_mt.rows()
    rows_mt = hl.MatrixTable.from_rows_table(vcf_variant_ht).key_cols_by(s="foo")
    hl.export_vcf(
        rows_mt,
        sites_vcf_path,
        metadata=vcf_meta,
        append_to_header=vcf_header_file,
        tabix=True,
    )  # Sites-only VCF for external use

    logger.info("All annotation steps are completed")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="This script adds variant annotations to the mitochondria VCF/MT"
    )
    parser.add_argument("-m", "--mt-path", help="Path to combined mt", required=True)
    parser.add_argument(
        "-d",
        "--output-dir",
        help="Path to directory to which output should be written",
        required=True,
    )
    parser.add_argument(
        "-a",
        "--participant-data",
        help="Output file that results from Terra data download",
        required=True,
    )
    parser.add_argument(
        "-v",
        "--vep-results",
        help="MatrixTable path to output vep results (either the existing results or where to ouput new vep results if also setting run_vep)",
        required=True,
    )
    parser.add_argument(
        "--slack-token", help="Slack token that allows integration with slack",
    )
    parser.add_argument(
        "--slack-channel", help="Slack channel to post results and notifications to",
    )
    parser.add_argument(
        "--min-het-threshold",
        help="Minimum heteroplasmy level to define a variant as a PASS heteroplasmic variant, genotypes below this threshold will count towards the heteroplasmy_below_min_het_threshold filter and be set to missing",
        type=float,
        default=0.10,
    )
    parser.add_argument(
        "--min-hom-threshold",
        help="Minimum heteroplasmy level to define a variant as homoplasmic",
        type=float,
        default=0.95,
    )
    parser.add_argument(
        "--vaf-filter-threshold",
        help="Should match vaf_filter_threshold supplied to Mutect2, variants below this value will be set to homoplasmic reference after calculating the common_low_heteroplasmy filter",
        type=float,
        default=0.01,
    )
    parser.add_argument(
        "--subset-to-gnomad-release",
        help="Set to True to only include released gnomAD samples",
        action="store_true",
    )
    parser.add_argument(
        "--keep-all-samples",
        help="Set to True to keep all samples (will skip steps that filter samples because of contamination and/or mitochondrial copy number)",
        action="store_true",
    )
    parser.add_argument(
        "--run-vep", help="Set to True to run/rerun vep", action="store_true"
    )
    parser.add_argument(
        "--overwrite", help="Overwrites existing files", action="store_true"
    )

    args = parser.parse_args()

    # Both a slack token and slack channel must be supplied to receive notifications on slack
    if args.slack_channel and args.slack_token:
        with slack_notifications(args.slack_token, args.slack_channel):
            main(args)
    else:
        main(args)
